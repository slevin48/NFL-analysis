#!/usr/bin/env python3
"""Compute TV Clutch Factor scores for quarterbacks using clutch play-by-play data."""

from __future__ import annotations

import argparse
import pathlib
from typing import Iterable

import numpy as np
import pandas as pd


CLUTCH_DATA_DEFAULT = pathlib.Path("data/pbp_last_25_seasons_clutch.parquet")


def parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Load clutch play-by-play data and aggregate quarterback passing stats "
            "into a TV Clutch Factor score."
        )
    )
    parser.add_argument(
        "--input",
        type=pathlib.Path,
        default=CLUTCH_DATA_DEFAULT,
        help=(
            "Path to the clutch play-by-play dataset generated by download_pbp.py. "
            "Supports Parquet (.parquet) and CSV (.csv) files. (default: %(default)s)"
        ),
    )
    parser.add_argument(
        "--output",
        type=pathlib.Path,
        help=(
            "Optional path to write the quarterback leaderboard. The format is "
            "inferred from the extension (.parquet or .csv)."
        ),
    )
    parser.add_argument(
        "--top",
        type=int,
        default=10,
        help="Number of quarterbacks to display in the console output. (default: %(default)s)",
    )
    return parser.parse_args(argv)


def load_clutch_data(path: pathlib.Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(
            f"Clutch dataset not found at {path}. Run download_pbp.py to generate it."
        )

    if path.suffix.lower() == ".parquet":
        return pd.read_parquet(path)
    if path.suffix.lower() == ".csv":
        return pd.read_csv(path)
    raise ValueError("Unsupported input format. Use a .parquet or .csv file.")


def compute_tv_clutch_factor(pbp: pd.DataFrame) -> pd.DataFrame:
    required_columns = {
        "passer_player_id",
        "passer_player_name",
        "pass_attempt",
        "complete_pass",
        "pass_touchdown",
        "interception",
        "yards_gained",
    }
    missing_columns = required_columns - set(pbp.columns)
    if missing_columns:
        missing = ", ".join(sorted(missing_columns))
        raise KeyError(f"Input data missing required columns: {missing}")

    passing_plays = pbp.loc[pbp["pass_attempt"] == 1].copy()
    grouped = (
        passing_plays.groupby(["passer_player_id", "passer_player_name"], dropna=False)
        .agg(
            clutch_attempts=("pass_attempt", "sum"),
            completions=("complete_pass", "sum"),
            touchdowns=("pass_touchdown", "sum"),
            interceptions=("interception", "sum"),
            yards_gained=("yards_gained", "sum"),
        )
        .reset_index()
    )

    grouped = grouped[grouped["clutch_attempts"] > 0].copy()
    grouped["passer_player_name"] = grouped["passer_player_name"].fillna("Unknown")
    grouped["completion_pct"] = grouped["completions"] / grouped["clutch_attempts"] * 100

    attempts = grouped["clutch_attempts"].astype(float)
    grouped["yards_per_attempt"] = grouped["yards_gained"] / attempts
    grouped["td_per_attempt"] = grouped["touchdowns"] / attempts
    grouped["int_per_attempt"] = grouped["interceptions"] / attempts

    def clamp(series: pd.Series) -> pd.Series:
        return series.clip(lower=0.0, upper=2.375)

    a = clamp((grouped["completion_pct"] / 100 - 0.3) * 5)
    b = clamp((grouped["yards_per_attempt"] - 3) * 0.25)
    c = clamp(grouped["td_per_attempt"] * 20)
    d = clamp(2.375 - grouped["int_per_attempt"] * 25)

    grouped["passer_rating"] = ((a + b + c + d) / 6) * 100
    grouped["tv_clutch_factor"] = grouped["passer_rating"] * (1 + np.log1p(attempts))

    grouped.sort_values("tv_clutch_factor", ascending=False, inplace=True)
    columns_order = [
        "passer_player_id",
        "passer_player_name",
        "clutch_attempts",
        "completions",
        "completion_pct",
        "yards_gained",
        "touchdowns",
        "interceptions",
        "passer_rating",
        "tv_clutch_factor",
    ]
    return grouped.loc[:, columns_order]


def save_leaderboard(df: pd.DataFrame, output_path: pathlib.Path) -> None:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    suffix = output_path.suffix.lower()
    if suffix == ".parquet":
        df.to_parquet(output_path, index=False)
    elif suffix == ".csv":
        df.to_csv(output_path, index=False)
    elif suffix == ".json":
        df.to_json(output_path, orient="records", indent=2)
    else:
        raise ValueError(
            "Unsupported output format. Use a .parquet, .csv, or .json extension."
        )


def main(argv: Iterable[str] | None = None) -> None:
    args = parse_args(argv)
    pbp = load_clutch_data(args.input)
    leaderboard = compute_tv_clutch_factor(pbp)

    display = leaderboard.head(args.top)
    with pd.option_context("display.max_columns", None):
        print(
            display.to_string(
                index=False,
                formatters={
                    "completion_pct": "{:.2f}".format,
                    "passer_rating": "{:.2f}".format,
                    "tv_clutch_factor": "{:.2f}".format,
                },
            )
        )

    if args.output is not None:
        save_leaderboard(leaderboard, args.output)
        print(f"Saved leaderboard to {args.output.resolve()}")


if __name__ == "__main__":
    main()

